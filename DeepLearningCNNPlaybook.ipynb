{"cells":[{"cell_type":"markdown","source":"# Notebook Styling: Please do not edit","metadata":{"cell_id":"952593440648454984a4d07368d0c01a","deepnote_cell_height":82,"deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"#import os\n#os.system (\"pip install keras==2.4.3\")\n\nimport keras\nprint('The keras version is {}.'.format(keras.__version__))","metadata":{"cell_id":"8ab235e59cb74080bfc54635e4de7982","source_hash":"859d51c3","execution_start":1677201854122,"execution_millis":1551,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stderr","text":"2023-02-24 01:24:14.243669: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\nThe keras version is 2.9.0.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# IPython display functions\nimport IPython\nfrom IPython.display import display, HTML, SVG, Image\n\n# General Plotting\nimport matplotlib.pyplot as plt\n\nplt.style.use('seaborn-paper')\nplt.rcParams['figure.figsize'] = [10, 6] ## plot size\nplt.rcParams['axes.linewidth'] = 2.0 #set the value globally\n\n## notebook style and settings\ndisplay(HTML(\"<style>.container { width:90% !important; }</style>\"))\ndisplay(HTML(\"<style>.output_png { display: table-cell; text-align: center; vertical-align: middle; } </style>\"))\ndisplay(HTML(\"<style>.MathJax {font-size: 100%;}</style>\"))\n\n# For changing background color\ndef set_background(color):\n    script = ( \"var cell = this.closest('.code_cell');\" \"var editor = cell.querySelector('.input_area');\" \"editor.style.background='{}';\" \"this.parentNode.removeChild(this)\" ).format(color)\n    display(HTML('<img src onerror=\"{}\">'.format(script)))","metadata":{"cell_id":"cbd26b3bd6da440aacae2b2c37634386","source_hash":"4437f931","execution_start":1677201855676,"execution_millis":482,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_3779/3485464767.py:8: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n  plt.style.use('seaborn-paper')\n","output_type":"stream"},{"data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>.container { width:90% !important; }</style>"},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>.output_png { display: table-cell; text-align: center; vertical-align: middle; } </style>"},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>.MathJax {font-size: 100%;}</style>"},"metadata":{},"output_type":"display_data"}],"execution_count":2},{"cell_type":"markdown","source":"Library Imports","metadata":{"cell_id":"a35cf411cb4e4808b0dc6f9cb74048d4","deepnote_cell_height":52.390625,"deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"import os\nimport sys\nimport random\nimport numpy as np\nimport pandas as pd\nfrom os import walk\n\n# Metrics\nfrom sklearn.metrics import *\n\n# Keras library for deep learning\n# https://keras.io/\nimport tensorflow as tf\nimport keras\nfrom keras.datasets import mnist # MNIST Data set\nfrom keras.models import Sequential # Model building\nfrom keras.layers import * # Model layers\nfrom keras.preprocessing.image import *\nfrom tensorflow.keras.utils import *\nfrom sklearn.model_selection import train_test_split\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)","metadata":{"cell_id":"64fabdd38f1a462088674582fb3ea2f7","source_hash":"3cfdb3f9","execution_start":1677201856160,"execution_millis":634,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# 1. Helper Functions","metadata":{"cell_id":"2873628790ab49bcbf8f9c2dc603e7bb","deepnote_cell_height":82,"deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"## 1.1 Confusion Matrix\nConfusion matrices are an important toolkit in every data scientist's box. We have created a function for you that you can use to create visual confusion matrices and analyze your models.","metadata":{"cell_id":"614d8ae5eca34d9eb442d7dbc612083c","deepnote_cell_height":130.796875,"deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"def displayConfusionMatrix(confusionMatrix, precisionNegative, precisionPositive, recallNegative, recallPositive, title):\n    # Set font size for the plots. You can ignore this line.\n    PLOT_FONT_SIZE = 14\n    \n    # Set plot size. Please ignore this line\n    plt.rcParams['figure.figsize'] = [5, 5]\n    \n    # Transpose of confusion matrix to align the plot with the actual precision recall values. Please ignore this as well.\n    confusionMatrix = np.transpose(confusionMatrix)\n    \n    # Plotting the confusion matrix\n    plt.imshow(confusionMatrix, interpolation='nearest',cmap=plt.cm.Blues, vmin=0, vmax=100)\n    \n    \n    # Setting plot properties. You should ignore everything from here on.\n    xticks = np.array([-0.5, 0, 1,1.5])\n    plt.gca().set_xticks(xticks)\n    plt.gca().set_yticks(xticks)\n    plt.gca().set_xticklabels([\"\", \"Healthy\\nRecall=\" + str(recallNegative) , \"Pneumonia\\nRecall=\" + str(recallPositive), \"\"], fontsize=PLOT_FONT_SIZE)\n    plt.gca().set_yticklabels([\"\", \"Healthy\\nPrecision=\" + str(precisionNegative) , \"Pneumonia\\nPrecision=\" + str(precisionPositive), \"\"], fontsize=PLOT_FONT_SIZE)\n    plt.ylabel(\"Predicted Class\", fontsize=PLOT_FONT_SIZE)\n    plt.xlabel(\"Actual Class\", fontsize=PLOT_FONT_SIZE)\n    plt.title(title, fontsize=PLOT_FONT_SIZE)\n        \n    # Add text in heatmap boxes\n    for i in range(2):\n        for j in range(2):\n            text = plt.text(j, i, confusionMatrix[i][j], ha=\"center\", va=\"center\", color=\"white\", size=15) ### size here is the size of text inside a single box in the heatmap\n            \n    plt.show()","metadata":{"cell_id":"d40340c4f5d04ee89a3fc1fa1087e21d","source_hash":"ca9c6cb7","execution_start":1677201856800,"execution_millis":0,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def calculateMetrics(predictions, predictionsProbabilities, actualLabels):\n    # Convert label format from [0,1](label 1) and [1,0](label 0) into single integers: 1 and 0.\n    actualLabels = [item[1] for item in actualLabels]\n    \n    # Get probabilities for the class with label 1. That is all we need to compute AUCs. We don't need probabilities for class 0.\n    predictionsProbabilities = [item[1] for item in predictionsProbabilities]\n    \n    # Calculate metrics using scikit-learn functions. The round function is used to round the numbers up to 2 decimal points.\n    try:\n        accuracy = round(accuracy_score(actualLabels, predictions) * 100, 2)\n        precisionNegative = round(precision_score(actualLabels, predictions, average = None)[0] * 100, 2)\n        precisionPositive = round(precision_score(actualLabels, predictions, average = None)[1] * 100, 2)\n        recallNegative = round(recall_score(actualLabels, predictions, average = None)[0] * 100, 2)\n        recallPositive = round(recall_score(actualLabels, predictions, average = None)[1] * 100, 2)\n    except:\n        print(\"An exception occurred but was caught.\")\n    auc = round(roc_auc_score(actualLabels, predictionsProbabilities) * 100, 2)\n    \n    return auc","metadata":{"tags":[],"cell_id":"290f891443db43fdaaeeba8919c3e7b0","source_hash":"1e07d900","execution_start":1677201856805,"execution_millis":1,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## 1.2 Metrics Calculation\nWe are giving you a function that will calculate all the metrics you'll need in order to analyze your model","metadata":{"cell_id":"2373610a400746aa9565013c03d02941","deepnote_cell_height":108.390625,"deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"def calculateMetricsAndPrint(predictions, predictionsProbabilities, actualLabels):\n    # Convert label format from [0,1](label 1) and [1,0](label 0) into single integers: 1 and 0.\n    actualLabels = [item[1] for item in actualLabels]\n    \n    # Get probabilities for the class with label 1. That is all we need to compute AUCs. We don't need probabilities for class 0.\n    predictionsProbabilities = [item[1] for item in predictionsProbabilities]\n    \n    # Calculate metrics using scikit-learn functions. The round function is used to round the numbers up to 2 decimal points.\n    accuracy = round(accuracy_score(actualLabels, predictions) * 100, 2)\n    precisionNegative = round(precision_score(actualLabels, predictions, average = None)[0] * 100, 2)\n    precisionPositive = round(precision_score(actualLabels, predictions, average = None)[1] * 100, 2)\n    recallNegative = round(recall_score(actualLabels, predictions, average = None)[0] * 100, 2)\n    recallPositive = round(recall_score(actualLabels, predictions, average = None)[1] * 100, 2)\n    auc = round(roc_auc_score(actualLabels, predictionsProbabilities) * 100, 2)\n    confusionMatrix = confusion_matrix(actualLabels, predictions)\n    \n    # Print metrics. .%2f prints a number upto 2 decimal points only.\n    print(\"------------------------------------------------------------------------\")\n    print(\"Accuracy: %.2f\\nPrecisionNegative: %.2f\\nPrecisionPositive: %.2f\\nRecallNegative: %.2f\\nRecallPositive: %.2f\\nAUC Score: %.2f\" % \n          (accuracy, precisionNegative, precisionPositive, recallNegative, recallPositive, auc))\n    print(\"------------------------------------------------------------------------\")\n    \n    print(\"+ Printing confusion matrix...\\n\")\n    # Display confusion matrix\n    displayConfusionMatrix(confusionMatrix, precisionNegative, precisionPositive, recallNegative, recallPositive, \"Confusion Matrix\")\n    \n    print(\"+ Printing ROC curve...\\n\")\n    # ROC Curve\n    plt.rcParams['figure.figsize'] = [16, 8]\n    FONT_SIZE = 16\n    falsePositiveRateDt, truePositiveRateDt, _ = roc_curve(actualLabels, predictionsProbabilities)\n    plt.plot(falsePositiveRateDt, truePositiveRateDt, linewidth = 5, color='black')\n    plt.xticks(fontsize=FONT_SIZE)\n    plt.yticks(fontsize=FONT_SIZE)\n    plt.xlabel(\"False Positive Rate\", fontsize=FONT_SIZE)\n    plt.ylabel(\"True Positive Rate\", fontsize=FONT_SIZE)\n    plt.show()\n    \n    return auc","metadata":{"cell_id":"41a33e6f8b0d48d7adf2858fe024c67a","source_hash":"656e6053","execution_start":1677201856812,"execution_millis":1,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"## 1.3 Kaggle Predictions","metadata":{"cell_id":"773b5673892c4f32a1a6b37e555fcc78","deepnote_cell_height":70,"deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"def getKagglePredictions(model, kaggleData, filename):\n    print(\"+ Writing kaggle test results in : results/%s...\" % filename)\n    predictions = model.predict(kaggleData)\n    predictionProbs = [item[1] for item in predictions]\n        \n    # Store predictions for kaggle\n    outputFile = open(\"results/\" + str(filename), \"w\")\n    outputFile.write(\"Id,Prediction\\n\")\n    for i in range(0, len(predictionProbs)):\n        outputFile.write(str(i + 1) + \",\" + str(predictionProbs[i]) + \"\\n\")\n    \n    outputFile.close()","metadata":{"cell_id":"188910b6bb4e48e79aa10e78d244df3e","source_hash":"96bc1348","execution_start":1677201856816,"execution_millis":9,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"## 1.4 Top n% accuracy","metadata":{"cell_id":"0dbacff12b1e4ab78d9911d57d0ce4c5","deepnote_cell_height":70,"deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"def calculateClasswiseTopNAccuracy(actualLabels, predictionsProbs, TOP_N):\n    \"\"\"\n    TOP_N is the top n% predictions you want to use for each class\n    \"\"\"\n\n    discreteActualLabels = [1 if item[1] > item[0] else 0 for item in actualLabels]\n    discretePredictions = [1 if item[1] > item[0] else 0 for item in predictionsProbs]\n    predictionProbsTopNHealthy, predictionProbsTopNPneumonia = [item[0] for item in predictionsProbs], [item[1] for item in predictionsProbs]\n    predictionProbsTopNHealthy = list(reversed(sorted(predictionProbsTopNHealthy)))[:int(len(predictionProbsTopNHealthy) * TOP_N / 100)][-1]\n    predictionProbsTopNPneumonia = list(reversed(sorted(predictionProbsTopNPneumonia)))[:int(len(predictionProbsTopNPneumonia) * TOP_N / 100)][-1]\n\n    # Calculate accuracy for both classes\n    accuracyHealthy = []\n    accuracyPneumonia = []\n    for i in range(0, len(discretePredictions)):\n        if discretePredictions[i] == 1:\n            # Pneumonia\n            if predictionsProbs[i][1] > predictionProbsTopNPneumonia:\n                accuracyPneumonia.append(int(discreteActualLabels[i]) == 1)\n        else:\n            # Healthy\n            if predictionsProbs[i][0] > predictionProbsTopNHealthy:\n                accuracyHealthy.append(int(discreteActualLabels[i]) == 0)\n\n    accuracyHealthy = round((accuracyHealthy.count(True) * 100) / len(accuracyHealthy), 2)\n    accuracyPneumonia = round((accuracyPneumonia.count(True) * 100) / len(accuracyPneumonia), 2)\n    return accuracyHealthy, accuracyPneumonia","metadata":{"cell_id":"045e42b9780149128a85234552e6069a","source_hash":"8ea36c0f","owner_user_id":"17a5c176-c9f5-46e9-af17-ab5b0f1b5ce8","execution_start":1677201856825,"execution_millis":1,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"# 2. Data Loading\n## 2.1 Loading File Paths\nWe will first load file paths from normal and pneumonia folders in the train directory.","metadata":{"cell_id":"491dd133e3e94b35a4fc67b826bdb6e2","deepnote_cell_height":176.390625,"deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"# Load normal images\nnormalImagesPath = \"data/train/normal\"\nnormalImageFiles = []\nfor(_,_,files) in walk(normalImagesPath):\n    normalImageFiles.extend(files)\n\nnormalImagesPath2 = \"data/train/normal2\"\nfor(_,_,files) in walk(normalImagesPath2):\n    normalImageFiles.extend(files)\n\nprint(len(normalImageFiles))\n\n# Load pneumonia images\npneumoniaImagesPath = \"data/train/pneumonia\"\npneumoniaImageFiles = []\nfor(_,_,files) in walk(pneumoniaImagesPath):\n    pneumoniaImageFiles.extend(files)\n    \nrandom.shuffle(pneumoniaImageFiles)\npneumoniaImageFiles = pneumoniaImageFiles[:len(normalImageFiles)]\nprint(\"Normal X-ray images: %d\\nPneumonia X-ray images: %d\" % (len(normalImageFiles), len(pneumoniaImageFiles)))","metadata":{"cell_id":"d62b1c7e926d4ffebaf41667ee154889","source_hash":"932cd718","execution_start":1677201856868,"execution_millis":1,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"1436\nNormal X-ray images: 1436\nPneumonia X-ray images: 1436\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"## 2.2 Loading Image Data\n### 2.2.1 Training and Validation","metadata":{"cell_id":"abe45e8ba63c4a8fb920b8265dd07e60","deepnote_cell_height":118,"deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"imagesData = []\nimagesLabels = []\n\nfor file in normalImageFiles:\n    fullPath = normalImagesPath + \"/\" + file\n    if os.path.exists(fullPath) == False:\n            continue\n    imageData = load_img(normalImagesPath + \"/\" + file, color_mode = \"grayscale\") # load_img function comes from keras library when we do \"from keras.preprocessing.image import *\"\n    imageArray = img_to_array(imageData) / 255.0\n    \n    imagesData.append(imageArray)\n    imagesLabels.append(0)\n    \n\nfor file in pneumoniaImageFiles:\n    fullPath = pneumoniaImagesPath + \"/\" + file\n    if os.path.exists(fullPath) == False:\n            continue\n            \n    imageData = load_img(pneumoniaImagesPath + \"/\" + file, color_mode = \"grayscale\") # load_img function comes from keras library when we do \"from keras.preprocessing.image import *\"\n    imageArray = img_to_array(imageData) / 255.0\n    \n    imagesData.append(imageArray)\n    imagesLabels.append(1)\n\nimagesData = np.array(imagesData)\nimagesLabels = keras.utils.to_categorical(imagesLabels)\nprint(\"Input data shape: %s\" % (imagesData.shape,))","metadata":{"cell_id":"26711256930f40b9a5ba29beaaeb5460","source_hash":"cc7c3793","execution_start":1677201856868,"execution_millis":3561,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"Input data shape: (2154, 256, 256, 1)\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"### 2.2.2 Kaggle Testing Data","metadata":{"cell_id":"e31d9bfe2a254c0b8ee9f5efe3a8b526","deepnote_cell_height":62,"deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"testImagesPath = \"data/test/\"\ntestImageFiles = []\nfor(_,_,files) in walk(testImagesPath):\n    testImageFiles.extend(files)\ntestImageFiles = list(sorted(testImageFiles))\n    \nkaggleTestImages = []\nfor file in testImageFiles:\n    fullPath = testImagesPath + \"/\" + file\n    if os.path.exists(fullPath) == False:\n        continue\n    imageData = load_img(testImagesPath + \"/\" + file, color_mode = \"grayscale\") # load_img function comes from keras library when we do \"from keras.preprocessing.image import *\"\n    imageArray = img_to_array(imageData) / 255.0\n    \n    kaggleTestImages.append(imageArray)\n    \nkaggleTestImages = np.array(kaggleTestImages)\nprint(\"Number of test images: %d\" % len(kaggleTestImages))","metadata":{"cell_id":"20c49992f57b4ed2906aa7a8821c3cbe","source_hash":"e28f1a93","execution_start":1677201860430,"execution_millis":373,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"Number of test images: 200\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"## 2.3 Data Splitting into Training and Validation","metadata":{"cell_id":"0041b361cf3b448f80b51e9d08854c2f","deepnote_cell_height":70,"deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"def trainTestSplit(data, labels):\n    \"\"\"\n    80-20 train-test data split\n    \"\"\"\n    trainData, trainLabels, testData, testLabels = [], [], [], []\n    for i in range(0, len(data)):\n        if i % 6 == 0:\n            testData.append(data[i])\n            testLabels.append(labels[i])\n        else:\n            trainData.append(data[i])\n            trainLabels.append(labels[i])\n            \n    return np.array(trainData), np.array(testData), np.array(trainLabels), np.array(testLabels)","metadata":{"cell_id":"64d2afd98dba40f69307551ebe2c38a7","source_hash":"6029a050","execution_start":1677201860806,"execution_millis":1,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# In our context, since we have a private test data on kaggle, our test data here would actually mean validation data. We will use results on this validation(test) data to see how our model would perform on the actual test data.\n# Split data into 80% training and 20% testing\ntrainData, testData, trainLabels, testLabels = trainTestSplit(imagesData, imagesLabels)","metadata":{"cell_id":"50b8a9a971ea49ae97e1c956a14e907b","source_hash":"a389ed2a","execution_start":1677201860851,"execution_millis":103,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"# 3. Deep Learning Models\nWe will use keras to create deep learning models. Since we are dealing with images, we will use convolutional layers. For more details, please visit: https://keras.io/layers/convolutional/\n\n\n## 3.1 Parameterized Convolutional Neural Networks\nWe will first provide you with a simple function that takes in a few parameters and create a convolutional neural network model for you. This is the easiest way to create a CNN model.","metadata":{"cell_id":"0d32b6689e57479abed9a0522e8d3ebf","deepnote_cell_height":257.59375,"deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"def createParameterizedConvolutionalNeuralNetwork(trainImages, numLayers, numFilters, kernelSize, maxPooling, dropoutValue, learningRate, numClasses):\n    # Create model object\n    model = Sequential()\n    \n    # Add the first layer with dropout\n    model.add(Conv2D(numFilters, kernel_size=(kernelSize, kernelSize),\n                       activation='relu', padding = 'same',\n                     input_shape=trainImages.shape[1:]))\n    model.add(MaxPooling2D(pool_size=(maxPooling, maxPooling)))\n    model.add(Dropout(dropoutValue))\n    \n    while numLayers > 1:\n        model.add(Conv2D(numFilters, kernel_size=(kernelSize, kernelSize),\n                     activation='relu', padding = 'same'))\n        model.add(MaxPooling2D(pool_size=(maxPooling, maxPooling)))\n        model.add(Dropout(dropoutValue))\n        \n        numLayers = numLayers - 1\n        \n    # Convolutional layers are done, adding the remaining stuff. Please note that after conv layers, you should always use a Flatten() layer.\n    model.add(Flatten())\n    model.add(Dense(64, activation='relu'))\n    model.add(Dropout(dropoutValue))\n    model.add(Dense(numClasses, activation='softmax'))\n\n    # Compile model. You can skip this line.\n    model.compile(loss=keras.losses.categorical_crossentropy,\n                  optimizer=keras.optimizers.Adam(lr=learningRate),\n                  metrics=['accuracy'])\n    \n    # Return model\n    return model","metadata":{"cell_id":"73a69e0b989d49a6a122467654af6bb3","source_hash":"5c0a232b","execution_start":1677201860969,"execution_millis":0,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"## 3.2 More Nuanced Convolutional Neural Networks\nIn this section, we provide you with a function where you can edit tiny details of the model to see if it can give you a greater lift as compared to the parameterized model.","metadata":{"cell_id":"07cf88477dcd4ccab2e05c77db644165","deepnote_cell_height":130.796875,"deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"def createNuancedConvolutionalNeuralNetwork(trainImages, numClasses):\n    \"\"\"\n    You should try to edit this model as much as you can. Try adding/removing layers, setting different parameters for different layers etc. You have complete control of the model and you should try different things to see what works and what does not.\n    \"\"\"\n        # Create model object\n    model = Sequential()\n    \n    # Add the first layer with dropout\n    model.add(Conv2D(filters = 200, kernel_size=(3,3),\n                     activation='relu', padding = 'same',\n                     input_shape=trainImages.shape[1:]))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.3))\n    \n    # Second layer with diffefiltersrent parameters\n    model.add(Conv2D(filters = 150, kernel_size=(3,3),\n                     activation='relu', padding = 'same'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.2))\n     \n\n    # Convolutional layers are done, adding the remaining stuff. Please note that after conv layers, you should always use a Flatten() layer.\n    model.add(Flatten())\n    model.add(Dense(200, activation='relu'))\n    model.add(Dense(150, activation='relu'))\n    model.add(Dropout(0.2))\n    model.add(Dense(numClasses, activation='softmax'))\n\n    # Compile model. You can skip this line.\n    model.compile(loss=keras.losses.categorical_crossentropy,\n                  optimizer=keras.optimizers.Adam(lr=0.0001),\n                  metrics=['accuracy'])\n    \n    # Return model\n    return model","metadata":{"cell_id":"d7c52b75818848cc99c1921ed5cff3d5","source_hash":"eb129cf2","execution_start":1677201860970,"execution_millis":0,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"# 4. Model Training\n## 4.1 Data Augmentation\nDeep learning models require huge amounts of data for good performance. Since we only have around 5k examples, we will use what's called \"Data Augmentation\" to create more data. To read more on data augmentation, please visit: https://towardsdatascience.com/data-augmentation-for-deep-learning-4fe21d1a4eb9","metadata":{"cell_id":"9643970430b545bc82ac3ea311055675","deepnote_cell_height":221.1875,"deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"set_background('#fce53a')\n\n#####################################################################################################################################################\n# Things you can change                                                                                                                             \n#####################################################################################################################################################\n\n# You can change all these parameters for different results. Please go to the following links to read more about each parameter: \n# https://keras.io/preprocessing/image/\n# https://www.pyimagesearch.com/2019/07/08/keras-imagedatagenerator-and-data-augmentation/\ndataAugmentation = ImageDataGenerator(\n    rotation_range=0.5,\n    width_shift_range=0.02,\n    height_shift_range=0.02,\n    horizontal_flip=False,\n    vertical_flip=False,\n    #shear_range=0.02,\n    zoom_range=0.02)","metadata":{"cell_id":"041082d50b1e4f889b1fffe5a99c7f43","source_hash":"6d21c332","execution_start":1677201860970,"execution_millis":4,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<img src onerror=\"var cell = this.closest('.code_cell');var editor = cell.querySelector('.input_area');editor.style.background='#fce53a';this.parentNode.removeChild(this)\">"},"metadata":{},"output_type":"display_data"}],"execution_count":16},{"cell_type":"markdown","source":"## 4.2 Model Parameters","metadata":{"cell_id":"8fadb9f9da5e474798b0499691b20a95","deepnote_cell_height":70,"deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"set_background('#fce53a')\n\n#####################################################################################################################################################\n# Things you can change                                                                                                                             \n#####################################################################################################################################################\nnumLayers = 3 # Number of layers in the neural network\nnumFilters = 256 # Number of units in each layer\nkernelSize = 3 # filter size of a single filter\ndropoutValue = 0.4 # Dropout probability\nmaxPooling = 3 # Max pooling\nnumClasses = 2 # Don't change this value for pneumonia since we have 2 classes i.e we are trying to recognize a digit among 10 digits. But for any other data set, this should be changed\nbatchSize = 25 # How many images should a single batch contain\nlearningRate = 0.0002 # How fast should the model learn\nepochs = 40 # Number of epochs to train your model for\nUSE_DATA_AUGMENTATION = True # You can set it to false if you do not want to use data augmentation. We recommend trying both true and false.\n#####################################################################################################################################################\n\n\n# Please do not change this line.\ndataAugmentation.fit(trainData) # Training the augmentor in case we set USE_DATA_AUGMENTATION to True.","metadata":{"cell_id":"971a45be3ade4d64bf53997702cafa48","source_hash":"eb0ee00b","execution_start":1677201861019,"execution_millis":87,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<img src onerror=\"var cell = this.closest('.code_cell');var editor = cell.querySelector('.input_area');editor.style.background='#fce53a';this.parentNode.removeChild(this)\">"},"metadata":{},"output_type":"display_data"}],"execution_count":17},{"cell_type":"markdown","source":"## 4.3 Training and Validation","metadata":{"cell_id":"9a4557ad3ef84d538f63fa0d682aa34a","deepnote_cell_height":70,"deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"### 4.3.1 Model Instantiation","metadata":{"cell_id":"031269a9459c487cba30d41c80262889","deepnote_cell_height":62,"deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"# Create model\nparameterizedModel = createParameterizedConvolutionalNeuralNetwork(trainData, numLayers, numFilters, kernelSize, maxPooling, dropoutValue, learningRate, numClasses = 2)\nprint(\"+ Your parameterized model has been created...\")","metadata":{"cell_id":"ec47b291721345ecb2757eed93e46d39","source_hash":"ebe3f66e","execution_start":1677201861155,"execution_millis":46,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"+ Your parameterized model has been created...\n2023-02-24 01:24:21.107858: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: UNKNOWN ERROR (34)\n2023-02-24 01:24:21.107894: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (p-39b5d08b-2c44-4afa-9c43-9b247f743535): /proc/driver/nvidia/version does not exist\n2023-02-24 01:24:21.108113: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n  super(Adam, self).__init__(name, **kwargs)\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"# You can create the other model with the following line\nnonParameterizedModel = createNuancedConvolutionalNeuralNetwork(imagesData, numClasses = 2)\nprint(\"+ Your non parameterized model has been created...\")","metadata":{"cell_id":"6a37cfe93bbe4012b8c01d3c78745028","source_hash":"713b3f04","execution_start":1677201861200,"execution_millis":503,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"+ Your non parameterized model has been created...\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"#####################################################################################################################################################\n# Things you can change                                                                                                                             \n#####################################################################################################################################################\n\n# Please assign model the deep learning model you want to use i.e parameterizedModel or nonParameterizedModel\nmodel = nonParameterizedModel","metadata":{"cell_id":"2b7289fd01a14361af04adb1bf9a26f7","source_hash":"2b8304a6","execution_start":1677201861703,"execution_millis":14,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":"### 4.3.2 Model Training and Validation","metadata":{"cell_id":"a8ea2ec2de674fd28401ed91d00dd70f","deepnote_cell_height":62,"deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"bestAUC = 0.0\nbestEpoch = 0\nbestAccPredictions, bestAccPredictionProbabilities = [], []\n\nrandom.seed(4)\n\nprint(\"+ Starting training. Each epoch can take about 2-5 minutes, hold tight!\")\nprint(\"-----------------------------------------------------------------------\\n\")\nfor epoch in range(epochs):\n    \n    #################################################### Model Training ###############################################################\n    if USE_DATA_AUGMENTATION == True:\n        # Use data augmentation in alternate epochs\n        if epoch % 2 == 0:\n            # Alternate between training with and without augmented data. Training just on the augmented data might not be the best way to go.\n            ############ You can change the \"epoch % 2\" to some other integer value to train on top of the augmented data \n            ############ after a certain number of epochs e.g \"epoch % 3\" will train on augmented data after every 2 epochs ############\n            model.fit_generator(dataAugmentation.flow(trainData, trainLabels, batch_size=batchSize),\n                        steps_per_epoch=len(trainData) / batchSize, epochs=1, verbose = 2)\n        else:\n            model.fit(trainData, trainLabels, batch_size=batchSize, epochs=1, verbose = 2)\n    else:\n        # Do not use data augmentation\n        model.fit(trainData, trainLabels, batch_size=batchSize, epochs=1, verbose = 2)\n    #################################################### Model Testing ###############################################################\n    # Calculate test accuracy and AUC\n    accuracy = round(model.evaluate(testData, testLabels)[1] * 100, 3)\n    predictions = model.predict(testData)\n    AccPredictionProbabilities = model.predict(testData)\n    AccPredictions = [1 if item[1] > item[0] else 0 for item in AccPredictionProbabilities]\n    epochAUC = calculateMetrics(AccPredictions, AccPredictionProbabilities, testLabels)\n    print(\"+ Test accuracy at epoch %d is: %.2f \" % (epoch, accuracy))\n    print(\"+ Test AUC at epoch %d is: %.3f \" % (epoch, epochAUC))\n    outputFile = open(\"results/Log.txt\", \"a\")\n    outputFile.write(\"Epoch-Accuracy-AUC \\t %d \\t %.2f \\t %.3f \\n\" % (epoch, accuracy,epochAUC))\n    outputFile.close()\n    \n    #if accuracy > bestAcc:\n    if epochAUC > bestAUC:\n        bestEpoch = epoch\n        bestAUC = epochAUC\n        bestAUCPredictions = [1 if item[1] > item[0] else 0 for item in predictions]\n        bestAUCPredictionProbabilities = predictions\n        \n        ##################################### Store predictions for kaggle ###########################################################\n        kaggleResultsFileName = \"epoch-\" + str(epoch) + \"-results.csv\"\n        getKagglePredictions(model, kaggleTestImages, kaggleResultsFileName)\n        ##############################################################################################################################\n    print('\\n')\nprint(\"------------------------------------------------------------------------\")\n\n\n##################################################### Printing best metrics ##########################################################\n# Get more metrics for the best performing epoch\nprint(\"\\n*** Printing our best validation results that we obtained in epoch %d ...\" % bestEpoch)\ncalculateMetricsAndPrint(bestAUCPredictions, bestAUCPredictionProbabilities, testLabels)","metadata":{"cell_id":"5c3153be3b6c4f5b844b20e6fb704320","source_hash":"f090ecb3","execution_start":1677201861717,"execution_millis":8801764,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"+ Starting training. Each epoch can take about 2-5 minutes, hold tight!\n-----------------------------------------------------------------------\n\n/tmp/ipykernel_3779/528226091.py:19: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n  model.fit_generator(dataAugmentation.flow(trainData, trainLabels, batch_size=batchSize),\n71/71 - 361s - loss: 0.6320 - accuracy: 0.7031 - 361s/epoch - 5s/step\n12/12 [==============================] - 13s 1s/step - loss: 0.4784 - accuracy: 0.7994\n12/12 [==============================] - 12s 1s/step\n12/12 [==============================] - 12s 1s/step\n+ Test accuracy at epoch 0 is: 79.94 \n+ Test AUC at epoch 0 is: 92.460 \n+ Writing kaggle test results in : results/epoch-0-results.csv...\n7/7 [==============================] - 7s 970ms/step\n\n\n72/72 - 338s - loss: 0.3325 - accuracy: 0.8607 - 338s/epoch - 5s/step\n12/12 [==============================] - 12s 964ms/step - loss: 0.3688 - accuracy: 0.8691\n12/12 [==============================] - 11s 944ms/step\n12/12 [==============================] - 11s 930ms/step\n+ Test accuracy at epoch 1 is: 86.91 \n+ Test AUC at epoch 1 is: 95.550 \n+ Writing kaggle test results in : results/epoch-1-results.csv...\n7/7 [==============================] - 6s 868ms/step\n\n\n/tmp/ipykernel_3779/528226091.py:19: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n  model.fit_generator(dataAugmentation.flow(trainData, trainLabels, batch_size=batchSize),\n71/71 - 337s - loss: 0.2728 - accuracy: 0.8986 - 337s/epoch - 5s/step\n12/12 [==============================] - 12s 944ms/step - loss: 0.2576 - accuracy: 0.9053\n12/12 [==============================] - 11s 955ms/step\n12/12 [==============================] - 12s 963ms/step\n+ Test accuracy at epoch 2 is: 90.53 \n+ Test AUC at epoch 2 is: 97.020 \n+ Writing kaggle test results in : results/epoch-2-results.csv...\n7/7 [==============================] - 6s 903ms/step\n\n\n72/72 - 356s - loss: 0.1996 - accuracy: 0.9209 - 356s/epoch - 5s/step\n12/12 [==============================] - 12s 997ms/step - loss: 0.2455 - accuracy: 0.9248\n12/12 [==============================] - 12s 992ms/step\n12/12 [==============================] - 12s 1s/step\n+ Test accuracy at epoch 3 is: 92.48 \n+ Test AUC at epoch 3 is: 97.110 \n+ Writing kaggle test results in : results/epoch-3-results.csv...\n7/7 [==============================] - 7s 968ms/step\n\n\n/tmp/ipykernel_3779/528226091.py:19: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n  model.fit_generator(dataAugmentation.flow(trainData, trainLabels, batch_size=batchSize),\n71/71 - 337s - loss: 0.2222 - accuracy: 0.9203 - 337s/epoch - 5s/step\n12/12 [==============================] - 11s 902ms/step - loss: 0.2346 - accuracy: 0.9109\n12/12 [==============================] - 11s 937ms/step\n12/12 [==============================] - 12s 963ms/step\n+ Test accuracy at epoch 4 is: 91.09 \n+ Test AUC at epoch 4 is: 97.270 \n+ Writing kaggle test results in : results/epoch-4-results.csv...\n7/7 [==============================] - 6s 885ms/step\n\n\n72/72 - 335s - loss: 0.1464 - accuracy: 0.9409 - 335s/epoch - 5s/step\n12/12 [==============================] - 12s 956ms/step - loss: 0.2493 - accuracy: 0.9136\n12/12 [==============================] - 12s 973ms/step\n12/12 [==============================] - 12s 975ms/step\n+ Test accuracy at epoch 5 is: 91.36 \n+ Test AUC at epoch 5 is: 97.460 \n+ Writing kaggle test results in : results/epoch-5-results.csv...\n7/7 [==============================] - 6s 881ms/step\n\n\n/tmp/ipykernel_3779/528226091.py:19: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n  model.fit_generator(dataAugmentation.flow(trainData, trainLabels, batch_size=batchSize),\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"## 4.4 Top n% Predictions","metadata":{"cell_id":"a5eab50b211446bc9680cbcaec74247d","deepnote_cell_height":70,"deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"################################## You can change values inside the following list ###########################\ntopNValues = [5, 10, 20, 30]\n##############################################################################################################\n\naccuraciesHealthy, accuraciesPneumonia = [], []\nfor topn in topNValues:\n    accuracyHealthy, accuracyPneumonia = calculateClasswiseTopNAccuracy(testLabels, bestAccPredictionProbabilities, topn)\n    accuraciesHealthy.append(accuracyHealthy)\n    accuraciesPneumonia.append(accuracyPneumonia)\n    \n    print(\"+ Accuracy for top %d percent predictions for healthy: %.2f, pneumonia: %.2f\" % (topn, accuracyHealthy, accuracyPneumonia))\n    \n# Plot results\nx = np.arange(len(accuraciesHealthy))\nplt.plot(x, accuraciesHealthy, linewidth = 3, color = '#e01111')\nscatterHealthy = plt.scatter(x, accuraciesHealthy, marker = 's', s = 100, color = '#e01111')\nplt.plot(x, accuraciesPneumonia, linewidth = 3, color = '#0072ff')\nscatterPneumonia = plt.scatter(x, accuraciesPneumonia, marker = 'o', s = 100, color = '#0072ff')\nplt.xticks(x, topNValues, fontsize = 15)\nplt.yticks(fontsize = 15)\nplt.xlabel(\"Top N%\", fontsize = 15)\nplt.ylabel(\"Accuracy\", fontsize = 15)\nplt.legend([scatterHealthy, scatterPneumonia], [\"Accuracy for Healthy\", \"Accuracy for Pneumonia\"], fontsize = 17)\nplt.ylim(0, 110)\nplt.show()\n","metadata":{"cell_id":"692b70065a9d4742a3e50ba1bbd53984","source_hash":"e40791d1","execution_start":1677201582700,"execution_millis":330,"deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"outputs":[{"output_type":"error","ename":"IndexError","evalue":"list index out of range","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn [22], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m accuraciesHealthy, accuraciesPneumonia \u001b[38;5;241m=\u001b[39m [], []\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m topn \u001b[38;5;129;01min\u001b[39;00m topNValues:\n\u001b[0;32m----> 7\u001b[0m     accuracyHealthy, accuracyPneumonia \u001b[38;5;241m=\u001b[39m \u001b[43mcalculateClasswiseTopNAccuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtestLabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbestAccPredictionProbabilities\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtopn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     accuraciesHealthy\u001b[38;5;241m.\u001b[39mappend(accuracyHealthy)\n\u001b[1;32m      9\u001b[0m     accuraciesPneumonia\u001b[38;5;241m.\u001b[39mappend(accuracyPneumonia)\n","Cell \u001b[0;32mIn [8], line 9\u001b[0m, in \u001b[0;36mcalculateClasswiseTopNAccuracy\u001b[0;34m(actualLabels, predictionsProbs, TOP_N)\u001b[0m\n\u001b[1;32m      7\u001b[0m discretePredictions \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m item[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m item[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m predictionsProbs]\n\u001b[1;32m      8\u001b[0m predictionProbsTopNHealthy, predictionProbsTopNPneumonia \u001b[38;5;241m=\u001b[39m [item[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m predictionsProbs], [item[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m predictionsProbs]\n\u001b[0;32m----> 9\u001b[0m predictionProbsTopNHealthy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mreversed\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpredictionProbsTopNHealthy\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpredictionProbsTopNHealthy\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mTOP_N\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     10\u001b[0m predictionProbsTopNPneumonia \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28msorted\u001b[39m(predictionProbsTopNPneumonia)))[:\u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(predictionProbsTopNPneumonia) \u001b[38;5;241m*\u001b[39m TOP_N \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m100\u001b[39m)][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Calculate accuracy for both classes\u001b[39;00m\n","\u001b[0;31mIndexError\u001b[0m: list index out of range"]}],"execution_count":22},{"cell_type":"code","source":"","metadata":{"cell_id":"034b821487ae4665ac451d141a5dcfb3","source_hash":"b623e53d","execution_start":1673120486391,"execution_millis":1,"deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=39b5d08b-2c44-4afa-9c43-9b247f743535' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"tags":[],"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote":{},"kernelspec":{"name":"python3","language":"python","display_name":"Python 3"},"language_info":{"name":"python","version":"3.6.8","mimetype":"text/x-python","file_extension":".py","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"nbconvert_exporter":"python"},"deepnote_notebook_id":"91f92a705ca34c7e8ff26994a312ec5c","deepnote_execution_queue":[],"deepnote_persisted_session":{"createdAt":"2023-02-18T23:31:06.814Z"}}}